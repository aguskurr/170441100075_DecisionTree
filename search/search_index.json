{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"K-Means Clustering K-Means adalah suatu metode penganalisaan data atau metode Data Mining yang melakukan proses pemodelan tanpa supervisi (unsupervised) dan merupakan salah satu metode yang melakukan pengelompokan data dengan sistem partisi. Metode k-means berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Dengan kata lain, metode ini berusaha untuk meminimalkan variasi antar data yang ada di dalam suatu cluster dan memaksimalkan variasi dengan data yang ada di cluster lainnya. Objective function yang berusaha diminimalkan oleh k-means adalah: J (U, V) = SUM (k=1 to N) SUM (i=1 to c) (a_ik * (x_k, v_i)^2) dimana: U : Matriks keanggotaan data ke masing-masing cluster yang berisikan nilai 0 dan 1 V : Matriks centroid/rata-rata masing-masing cluster N : Jumlah data c : Jumlah cluster a_ik : Keanggotaan data ke-k ke cluster ke-i x_k : data ke-k v_i : Nilai centroid cluster ke-i Prosedur yang digunakan dalam melakukan optimasi menggunakan k-means adalah sebagai berikut: Step 1. Tentukan jumlah cluster Step 2. Alokasikan data ke dalam cluster secara random Step 3. Hitung centroid/rata-rata dari data yang ada di masing-masing cluster. Step 4. Alokasikan masing-masing data ke centroid/rata-rata terdekat Step 5. Kembali ke Step 3, apabila masih ada data yang berpindah cluster atau apabila perubahan nilai centroid, ada yang di atas nilai threshold yang ditentukan atau apabila perubahan nilai pada objective function yang digunakan, di atas nilai threshold yang ditentukan Centroid/rata-rata dari data yang ada di masing-masing cluster yang dihitung pada Step 3. didapatkan menggunakan rumus sebagai berikut: v_ij = SUM (k=0 to N_i) (x_kj) / N_i dimana: i,k : indeks dari cluster j : indeks dari variabel v_ij : centroid/rata-rata cluster ke-i untuk variabel ke-j x_kj : nilai data ke-k yang ada di dalam cluster tersebut untuk variabel ke-j N_i : Jumlah data yang menjadi anggota cluster ke-i Sedangkan pengalokasian data ke masing-masing cluster yang dilakukan pada Step 4. dilakukan secara penuh, dimana nilai yang memungkinkan untuk a_ik adalah 0 atau 1. Nilai 1 untuk data yang dialokasikan ke cluster dan nilai 0 untuk data yang dialokasikan ke cluster yang lain. Dalam menentukan apakah suatu data teralokasikan ke suatu cluster atau tidak, dapat dilakukan dengan menghitung jarak data tersebut ke masing-masing centroid/rata-rata masing-masing cluster. Dalam hal ini, a_ik akan bernilai 1 untuk cluster yang centroidnya terdekat dengan data tersebut, dan bernilai 0 untuk yang lainnya. Referensi: J. B. MacQueen (1967): \u201cSome Methods for classification and Analysis of Multivariate Observations, Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability\u201d, Berkeley, University of California Press, 1:281-297 J. A. Hartigan (1975) \u201cClustering Algorithms\u201d. Wiley. J. A. Hartigan and M. A. Wong (1979). \u201cA K-Means Clustering Algorithm\u201d. Applied Statistics 28 (1): 100\u2013108. Cluster Validity Criterion Untuk menentukan jumlah cluster yang paling tepat, saat menggunakan metode k-means dapat dilakukan dengan beberapa cara. Salah satunya adalah dengan cara manual yang saya jelaskan dalam posting saya tentang Akurasi Hasil Pemodelan K-Means yang sering juga direfer sebagai Bootstrapped Method . Selain itu ada beberapa cara yang lain yang juga bisa digunakan seperti di bawah ini. Elbow Criterion (RMSSDT dan RS) Elbow criterion adalah salah satu cara untuk menentukan jumlah cluster yang paling tepat untuk pemodelan k-means. Elbow criterion untuk k-means ini mengkombinasikan antara nilai RMSSTD dan RS statistics, dimana cluster yang paling tepat untuk suatu dataset ditentukan apabila perbedaan nilai antara RMSSTD dan RS menjadi berbanding terbalik dengan keadaan sebelumnya. RMSSTD (Root Means Square Standard Deviation) merupakan alat ukur tingkat kemiripan (homogeneity) data yang terdapat di dalam cluster yang ditemukan (within clusters). Makin rendah nilai RMSSTD makin mirip data di dalam cluster yang ditemukan. RMSSDT dihitung menggunakan rumus sebagai berikut: RMSSTD = SQRT (SUM(i=1 to k) SUM(j=1 to d) (SUM(k=1 to N_i) ((x_kj \u2013 mu_j)^2)) / SUM(i=1 to k) SUM(j=1 to d) (N_i \u2013 1)) RS (R Squared) digunakan untuk mengukur tingkat kesamaan atau ketidaksamaan antara cluster (between clusters). RS mempunyai nilai antara 0 dan 1. Nilai 0 untuk cluster yang sama dan 1 untuk cluster yang benar-benar berbeda. RS dihitung dengan rumus: RS = (SS_t \u2013 SS_w) / SS_t SS_t = SUM(j=1 to d) (SUM(k=1 to N) ((x_kj \u2013 mu_j)^2) dan SS_w = SUM(i=1 to k) SUM(j=1 to d) (SUM(k=1 to N_i) ((x_kj \u2013 mu_j)^2)) Notasi: x_kj : data ke-k yang ada di dalam cluster untuk dimensi ke-j mu_j : means/rata-rata nilai dari variabel dimensi ke-j N_i : jumlah data di dalam cluster ke-i N : jumlah data keseluruhan d : jumlah dimensi dari data k : jumlah cluster Elbow criterion adalah suatu modelling criterion yang bisa digunakan untuk menentukan jumlah cluster dengan melihat perubahan perbandingan antara nilai RMSSTD dan RS. Hal ini dilihat dengan membandingkan persentase tingkat perubahan kedua nilai (RMSSTD dan RS). Apabila muncul suatu keadaan yang berbanding terbalik dengan keadaan sebelumnya, maka titik sebelum terjadinya perubahan tersebut dianggap sebagai jumlah cluster yang paling tepat. Referensi: Subhash Sharma: Applied Multivariate Techniques, John Wiley & Sons, Inc., 1996. G-Means (Gaussian Means) G-Means berusaha menentukan jumlah cluster secara gradual dengan melihat apakah suatu cluster sudah dalam keadaan terdistribusi secara normal atau tidak. Kalau masih dianggap belum normal, maka akan dilihat apakah cluster tersebut masih bisa displit untuk dijadikan dua cluster. Hipotesis yang digunakan adalah: H0: Data di sekitar centroid disample dari suatu distribusi Gaussian. H1: Data di sekitar centroid tidak disample dari suatu distribusi Gaussian. Adapun algoritma yang digunakan untuk menentukan split atau tidak adalah sebagai berikut: 1. Tentukan confidence level Alpha untuk testing. 2. Tentukan dua centroid baru c1 dan c2. 3. Jalankan k-means terhadap dua centroid baru tersebut. 4. Tentukan vektor v yang menghubungkan antara centroid c1 dan c2 dimana v = c1 \u2013 c2. Kemudian proyeksikan data X ke v dengan rumus x\u2019 = (x,v)/||v||^2. X\u2019 merupakan representasi satu dimensi dari data yang diproyeksikan ke v. Hitung z = F(x\u2019), dimana z adalah bentuk normalisasi x\u2019. 5. Hitung nilai A_2 (Z) dengan rumus di bawah. Apabila A_2 (Z) berada di wilayah nilai non-critical pada confidence level Alpha, maka H0 diterima, dan centroid awal tetap digunakan dan centroid baru c1 dan c2 dihapus. Untuk keadaan sebaliknya, H0 harus ditolak dan centroid baru c1 dan c2 digunakan sebagai pengganti centroid awal. A_2 (Z) = A_2(Z)(1+4/n-25/(n^2)) dan A_2(Z) = -1/n * SUM (i=1 to n) ((2 i \u2013 1)(log(z_i)+log(1-z_(n+1-i))) \u2013 n dimana: n : Jumlah data Referensi: G. Hamerly and C. Elkan (2003). Learning the k in k-means . In Proceedings of 17th Neural Information Processing Systems. X-Means Merupakan suatu pengembangan k-means untuk menentukan jumlah cluster yang paling tepat untuk suatu dataset yang dianalisa. Adapun algoritma yang diterapkan di dalam metote ini adalah dengan menggabungkan algoritma k-means murni dan salah satu modelling criterion seperti Bayesian Information Criterion (BIC) atau Akaike Information Criterion (AIC) \u2013 penjelasan tentang kedua criteria ini ada di My Mixture Modelling Page . Algoritma yang diterapkan adalah sebagai berikut: Step 1: Tentukan jumlah cluster Step 2: Lakukan optimasi dengan k-means murni Step 3: Untuk setiap cluster yang dihasilkan split cluster menjadi dua dan bandingkan modelling score antara model dengan satu cluster dan model dengan dua cluster. Model dengan score yang lebih baik dipilih menjadi perwakilan model yang displit. Referensi Pelleg D. and Moore A. (2000). X-means: Extending K-means with Efficient Estimation of the Number of Clusters. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML). 727-734. K-Means Variances Fuzzy c-Means Variasi dalam hal penentuan nilai keanggotaan data ke masing-masing cluster. Fuzzy c-Means merupakan perkembangan dari metode k-means dengan memperhitungkan bahwa data dapat tergabung ke dalam ke dalam beberapa cluster dengan tingkat keanggotaan yang berbeda-beda. Tetapi sum total dari nilai keanggotaan data tersebut harus sama dengan 1. Misalnya data x1 bisa tergabung dengan cluster I dengan tingkat keanggotaan 0,7, dengan cluster II dengan tingkat keanggotaan 0,2 dan dengan cluster III dengan tingkat keanggotaan 0,1. Hal ini berbeda dengan k-means karena metode tersebut mengharuskan suatu data untuk menjadi anggota atau tidak sekalian. Algoritma yang digunakan dalam fuzzy c-means sama dengan algoritma yang digunakan dalam k-means. Tetapi objective function dan rumus yang digunakan untuk menghitung centroid/rata-rata berbeda. Di samping itu, dalam fuzzy c-means, tingkat keanggotaan, yang sering disebut dengan membership function, juga perlu di hitung. Objective function dan rumus-rumus yang digunakan adalah sebagai berikut: Objective function: J (U, V) = SUM (k=1 to N) SUM (i=1 to c) (u_ik^m * (x_k, v_i)^2) dimana: u_ik = membership function data ke i ke cluster ke k m = weighting exponent U, V, N, c, x_k dan v_i : sudah dijelaskan di objective function untuk k-means Rumus menghitung rata-rata/centroid: v_ij = SUM (k=1 to N_i) (u_ik^m * x_kj) / SUM (k=1 to N_i) (u_ik^m) Rumus menghitung membership function: u_ik = SUM (j=1 to c) ((x_k \u2013 v_i)/(x_k \u2013 v_j))^(2/(m-1)) Referensi: Bezdek, J.C. (1981). Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum Press, New York. K Harmonic Means Variasi dalam hal objective function yang digunakan. K Harmonic Means menggunakan suatu objective function untuk menghindarkan pengaruh yang besar dari data-data yang ada di sekitar cluster center. Untuk keperluan tersebut, di samping nilai keanggotaan dari data terhadap cluster, setiap data juga mempunyai nilai weight yang digunakan untuk meng-harmoni-kan pengaruh masing-masing data dalam pemodelan. Adapun objective function yang digunakan dalam metode ini adalah sebagai berikut: J (V) = SUM (k=1 to N) (c / (SUM (i=1 to c) (1/ (x_k- v_i)^p))) dimana: V : Matriks centroid/rata-rata masing-masing cluster N : Jumlah data c : Jumlah cluster v_i : Nilai centroid cluster ke-i p : suatu input parameter yang besarnya lebih dari atau sama dengan 2 Nilai membership function u_ik dan weight w_k dihitung dengan rumus sebagai berikut: u_ik = SUM (j=1 to c) ((x_k \u2013 v_i)/(x_k \u2013 v_j))^(-p-2) w_k = SUM (j=1 to c) (x_k \u2013 v_j)^(-p-2) / (SUM (j=1 to c) (x_k \u2013 v_j)^(-p))^2 Referensi: G. Hamerly and C. Elkan (2002). Altenatives to the k-means algorithm that find better clusterings . In Proceedings of the 11th International Conference on Information and Knowledge Management. pp. 600-607. Kernel K-means Variasi untuk sekumpulan data yang \u2018dianggap\u2019 terkelompok secara non-linear. K-means yang standar umumnya digunakan untuk mengelompokkan data yang secara umum datanya dipisahkan secara linear. Kalau data \u2018dianggap\u2019 terkelompok secara non-linear, k-means perlu dimodifikasi untuk dapat mengakomodasi ke-non-linear-an tersebut. Adapun metode yang diimplementasikan di dalam menyelesaikan permasalahan ini adalah dengan mengadopsi Kernel Trick dalam proses pengelompokan yang dilakukan. Perlu diketahui di sini, untuk bisa menerapkan Kernel Trick, data perlu untuk dipetakan terlebih dahulu ke bentuk data dengan dimensi yang lain, yang umumnya jumlah dimensinya lebih tinggi dengan fungsi THETA(x), yang artinya data x dipetakan dari dimensi awal ke dimensi yang lain (umumnya dimensi yang lebih tinggi). Adapun objective function yang digunakan untuk Kernel K-Means adalah: J (U, V) = SUM (k=1 to N) SUM (i=1 to c) (a_ik * (THETA(x_k), v_i)^2) dimana: U : Matriks keanggotaan data ke masing-masing cluster yang berisikan nilai 0 dan 1 V : Matriks centroid/rata-rata masing-masing cluster N : Jumlah data c : Jumlah cluster a_ik : Keanggotaan data ke-k ke cluster ke-i v_i : Nilai centroid cluster ke-i Rumus menghitung rata-rata/centroid: v_ij = SUM (k=0 to N_i) THETA (x_kj) / N_i yang tentunya tidak bisa dihitung, karena kita tidak bisa mengetahui nilai THETA (x_kj) secara langsung. Hal ini bisa diakali, dengan langsung menentukan nilai a_ik (yang nilainya adalah 1 atau 0), dimana a_ik bernilai 1 untuk data yang mempunyai jarak terdekat dengan centroid dan 0 untuk yang lainnya. Adapun jarak antara data dengan centroid dihitung dengan rumus berikut ini: (THETA(x_l),v_i)^2 = SUM (l=0 to N_i) THETA(x_lj) THETA(x_lj) \u2013 2 SUM (k,l=0 to N_i) THETA (x_lj) THETA (x_kj)/ N_i + SUM (k=0 to N_i) THETA (x_kj) THETA (x_kj)/ N_i Disini fungsi kernel disubstitusikan, sehingga jarak antara data dengan centroid dapat dihitung dengan rumus berikut ini: (THETA(x_l),v_i)^2 = SUM (l=0 to N_i) K(x_lj,x_lj) \u2013 2*SUM (k,l=0 to N_i) K (x_lj,x_kj)/ N_i + SUM (k=0 to N_i) K (x_kj,x_kj)/ N_i Data di-assign ke dalam kelompok yang jarak antara centroid dan data tersebut diminimalkan. Prosedur yang digunakan tetap sama dengan prosedur yang diterapkan pada standar k-means. Referensi M Girolami (2002). Mercer kernel-based clustering in feature space. Neural Networks, IEEE Transactions on, Vol. 13, No. 3., pp. 780-784. Inderjit S Dhillon, Yuqiang Guan, Brian Kulis (2004).Kernel k-means: spectral clustering and normalized cuts. pp. 551-556 K-Modes Variasi dalam hal data yang dianalisa bukan continuous, tapi categorical. Untuk data categorical, k-means tidak bisa digunakan karena data categorical tidak bisa dicari nilai means (rata-rata)-nya. Untuk keperluan tersebut K-Modes dapat digunakan sebagai gantinya. Adapun algoritma yang digunakan sama dengan k-means dengan beberapa modifikasi sebagai berikut: Step 1. Tentukan jumlah cluster Step 2. Alokasikan data ke dalam cluster secara random Step 3. Hitung modes dari data yang ada di masing-masing cluster. Step 4. Alokasikan masing-masing data ke cluster terdekat menggunakan Hemming Distance Step 5. Kembali ke Step 3, apabila masih ada data yang berpindah cluster atau apabila perubahan nilai modes atau apabila perubahan nilai pada objective function yang digunakan, di atas nilai threshold yang ditentukan Objective function yang digunakan k-modes adalah: J (A, M) = SUM (k=1 to N) SUM (i=1 to c) (a_ik * D(x_k, m_i)) dimana: A : Matriks keanggotaan data ke masing-masing cluster yang berisikan nilai 0 dan 1 M : Matriks modes masing-masing cluster N : Jumlah data c : Jumlah cluster a_ik : Keanggotaan data ke-k ke cluster ke-i x_k : data ke-k m_i : Nilai modes cluster ke-i D(x_k, m_i) : Hemming Distance antara data x dan modes m Referensi: Chaturvedi, A.D., Green, P.E. and Carroll, J.D. (2001). K-Modes Clustering. Journal of Classification, 18, 35-56.","title":"Apa itu K-Means clustering ?"},{"location":"#k-means-clustering","text":"K-Means adalah suatu metode penganalisaan data atau metode Data Mining yang melakukan proses pemodelan tanpa supervisi (unsupervised) dan merupakan salah satu metode yang melakukan pengelompokan data dengan sistem partisi. Metode k-means berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Dengan kata lain, metode ini berusaha untuk meminimalkan variasi antar data yang ada di dalam suatu cluster dan memaksimalkan variasi dengan data yang ada di cluster lainnya. Objective function yang berusaha diminimalkan oleh k-means adalah: J (U, V) = SUM (k=1 to N) SUM (i=1 to c) (a_ik * (x_k, v_i)^2) dimana: U : Matriks keanggotaan data ke masing-masing cluster yang berisikan nilai 0 dan 1 V : Matriks centroid/rata-rata masing-masing cluster N : Jumlah data c : Jumlah cluster a_ik : Keanggotaan data ke-k ke cluster ke-i x_k : data ke-k v_i : Nilai centroid cluster ke-i Prosedur yang digunakan dalam melakukan optimasi menggunakan k-means adalah sebagai berikut: Step 1. Tentukan jumlah cluster Step 2. Alokasikan data ke dalam cluster secara random Step 3. Hitung centroid/rata-rata dari data yang ada di masing-masing cluster. Step 4. Alokasikan masing-masing data ke centroid/rata-rata terdekat Step 5. Kembali ke Step 3, apabila masih ada data yang berpindah cluster atau apabila perubahan nilai centroid, ada yang di atas nilai threshold yang ditentukan atau apabila perubahan nilai pada objective function yang digunakan, di atas nilai threshold yang ditentukan Centroid/rata-rata dari data yang ada di masing-masing cluster yang dihitung pada Step 3. didapatkan menggunakan rumus sebagai berikut: v_ij = SUM (k=0 to N_i) (x_kj) / N_i dimana: i,k : indeks dari cluster j : indeks dari variabel v_ij : centroid/rata-rata cluster ke-i untuk variabel ke-j x_kj : nilai data ke-k yang ada di dalam cluster tersebut untuk variabel ke-j N_i : Jumlah data yang menjadi anggota cluster ke-i Sedangkan pengalokasian data ke masing-masing cluster yang dilakukan pada Step 4. dilakukan secara penuh, dimana nilai yang memungkinkan untuk a_ik adalah 0 atau 1. Nilai 1 untuk data yang dialokasikan ke cluster dan nilai 0 untuk data yang dialokasikan ke cluster yang lain. Dalam menentukan apakah suatu data teralokasikan ke suatu cluster atau tidak, dapat dilakukan dengan menghitung jarak data tersebut ke masing-masing centroid/rata-rata masing-masing cluster. Dalam hal ini, a_ik akan bernilai 1 untuk cluster yang centroidnya terdekat dengan data tersebut, dan bernilai 0 untuk yang lainnya. Referensi: J. B. MacQueen (1967): \u201cSome Methods for classification and Analysis of Multivariate Observations, Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability\u201d, Berkeley, University of California Press, 1:281-297 J. A. Hartigan (1975) \u201cClustering Algorithms\u201d. Wiley. J. A. Hartigan and M. A. Wong (1979). \u201cA K-Means Clustering Algorithm\u201d. Applied Statistics 28 (1): 100\u2013108. Cluster Validity Criterion Untuk menentukan jumlah cluster yang paling tepat, saat menggunakan metode k-means dapat dilakukan dengan beberapa cara. Salah satunya adalah dengan cara manual yang saya jelaskan dalam posting saya tentang Akurasi Hasil Pemodelan K-Means yang sering juga direfer sebagai Bootstrapped Method . Selain itu ada beberapa cara yang lain yang juga bisa digunakan seperti di bawah ini. Elbow Criterion (RMSSDT dan RS) Elbow criterion adalah salah satu cara untuk menentukan jumlah cluster yang paling tepat untuk pemodelan k-means. Elbow criterion untuk k-means ini mengkombinasikan antara nilai RMSSTD dan RS statistics, dimana cluster yang paling tepat untuk suatu dataset ditentukan apabila perbedaan nilai antara RMSSTD dan RS menjadi berbanding terbalik dengan keadaan sebelumnya. RMSSTD (Root Means Square Standard Deviation) merupakan alat ukur tingkat kemiripan (homogeneity) data yang terdapat di dalam cluster yang ditemukan (within clusters). Makin rendah nilai RMSSTD makin mirip data di dalam cluster yang ditemukan. RMSSDT dihitung menggunakan rumus sebagai berikut: RMSSTD = SQRT (SUM(i=1 to k) SUM(j=1 to d) (SUM(k=1 to N_i) ((x_kj \u2013 mu_j)^2)) / SUM(i=1 to k) SUM(j=1 to d) (N_i \u2013 1)) RS (R Squared) digunakan untuk mengukur tingkat kesamaan atau ketidaksamaan antara cluster (between clusters). RS mempunyai nilai antara 0 dan 1. Nilai 0 untuk cluster yang sama dan 1 untuk cluster yang benar-benar berbeda. RS dihitung dengan rumus: RS = (SS_t \u2013 SS_w) / SS_t SS_t = SUM(j=1 to d) (SUM(k=1 to N) ((x_kj \u2013 mu_j)^2) dan SS_w = SUM(i=1 to k) SUM(j=1 to d) (SUM(k=1 to N_i) ((x_kj \u2013 mu_j)^2)) Notasi: x_kj : data ke-k yang ada di dalam cluster untuk dimensi ke-j mu_j : means/rata-rata nilai dari variabel dimensi ke-j N_i : jumlah data di dalam cluster ke-i N : jumlah data keseluruhan d : jumlah dimensi dari data k : jumlah cluster Elbow criterion adalah suatu modelling criterion yang bisa digunakan untuk menentukan jumlah cluster dengan melihat perubahan perbandingan antara nilai RMSSTD dan RS. Hal ini dilihat dengan membandingkan persentase tingkat perubahan kedua nilai (RMSSTD dan RS). Apabila muncul suatu keadaan yang berbanding terbalik dengan keadaan sebelumnya, maka titik sebelum terjadinya perubahan tersebut dianggap sebagai jumlah cluster yang paling tepat. Referensi: Subhash Sharma: Applied Multivariate Techniques, John Wiley & Sons, Inc., 1996. G-Means (Gaussian Means) G-Means berusaha menentukan jumlah cluster secara gradual dengan melihat apakah suatu cluster sudah dalam keadaan terdistribusi secara normal atau tidak. Kalau masih dianggap belum normal, maka akan dilihat apakah cluster tersebut masih bisa displit untuk dijadikan dua cluster. Hipotesis yang digunakan adalah: H0: Data di sekitar centroid disample dari suatu distribusi Gaussian. H1: Data di sekitar centroid tidak disample dari suatu distribusi Gaussian. Adapun algoritma yang digunakan untuk menentukan split atau tidak adalah sebagai berikut: 1. Tentukan confidence level Alpha untuk testing. 2. Tentukan dua centroid baru c1 dan c2. 3. Jalankan k-means terhadap dua centroid baru tersebut. 4. Tentukan vektor v yang menghubungkan antara centroid c1 dan c2 dimana v = c1 \u2013 c2. Kemudian proyeksikan data X ke v dengan rumus x\u2019 = (x,v)/||v||^2. X\u2019 merupakan representasi satu dimensi dari data yang diproyeksikan ke v. Hitung z = F(x\u2019), dimana z adalah bentuk normalisasi x\u2019. 5. Hitung nilai A_2 (Z) dengan rumus di bawah. Apabila A_2 (Z) berada di wilayah nilai non-critical pada confidence level Alpha, maka H0 diterima, dan centroid awal tetap digunakan dan centroid baru c1 dan c2 dihapus. Untuk keadaan sebaliknya, H0 harus ditolak dan centroid baru c1 dan c2 digunakan sebagai pengganti centroid awal. A_2 (Z) = A_2(Z)(1+4/n-25/(n^2)) dan A_2(Z) = -1/n * SUM (i=1 to n) ((2 i \u2013 1)(log(z_i)+log(1-z_(n+1-i))) \u2013 n dimana: n : Jumlah data Referensi: G. Hamerly and C. Elkan (2003). Learning the k in k-means . In Proceedings of 17th Neural Information Processing Systems. X-Means Merupakan suatu pengembangan k-means untuk menentukan jumlah cluster yang paling tepat untuk suatu dataset yang dianalisa. Adapun algoritma yang diterapkan di dalam metote ini adalah dengan menggabungkan algoritma k-means murni dan salah satu modelling criterion seperti Bayesian Information Criterion (BIC) atau Akaike Information Criterion (AIC) \u2013 penjelasan tentang kedua criteria ini ada di My Mixture Modelling Page . Algoritma yang diterapkan adalah sebagai berikut: Step 1: Tentukan jumlah cluster Step 2: Lakukan optimasi dengan k-means murni Step 3: Untuk setiap cluster yang dihasilkan split cluster menjadi dua dan bandingkan modelling score antara model dengan satu cluster dan model dengan dua cluster. Model dengan score yang lebih baik dipilih menjadi perwakilan model yang displit. Referensi Pelleg D. and Moore A. (2000). X-means: Extending K-means with Efficient Estimation of the Number of Clusters. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML). 727-734. K-Means Variances Fuzzy c-Means Variasi dalam hal penentuan nilai keanggotaan data ke masing-masing cluster. Fuzzy c-Means merupakan perkembangan dari metode k-means dengan memperhitungkan bahwa data dapat tergabung ke dalam ke dalam beberapa cluster dengan tingkat keanggotaan yang berbeda-beda. Tetapi sum total dari nilai keanggotaan data tersebut harus sama dengan 1. Misalnya data x1 bisa tergabung dengan cluster I dengan tingkat keanggotaan 0,7, dengan cluster II dengan tingkat keanggotaan 0,2 dan dengan cluster III dengan tingkat keanggotaan 0,1. Hal ini berbeda dengan k-means karena metode tersebut mengharuskan suatu data untuk menjadi anggota atau tidak sekalian. Algoritma yang digunakan dalam fuzzy c-means sama dengan algoritma yang digunakan dalam k-means. Tetapi objective function dan rumus yang digunakan untuk menghitung centroid/rata-rata berbeda. Di samping itu, dalam fuzzy c-means, tingkat keanggotaan, yang sering disebut dengan membership function, juga perlu di hitung. Objective function dan rumus-rumus yang digunakan adalah sebagai berikut: Objective function: J (U, V) = SUM (k=1 to N) SUM (i=1 to c) (u_ik^m * (x_k, v_i)^2) dimana: u_ik = membership function data ke i ke cluster ke k m = weighting exponent U, V, N, c, x_k dan v_i : sudah dijelaskan di objective function untuk k-means Rumus menghitung rata-rata/centroid: v_ij = SUM (k=1 to N_i) (u_ik^m * x_kj) / SUM (k=1 to N_i) (u_ik^m) Rumus menghitung membership function: u_ik = SUM (j=1 to c) ((x_k \u2013 v_i)/(x_k \u2013 v_j))^(2/(m-1)) Referensi: Bezdek, J.C. (1981). Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum Press, New York. K Harmonic Means Variasi dalam hal objective function yang digunakan. K Harmonic Means menggunakan suatu objective function untuk menghindarkan pengaruh yang besar dari data-data yang ada di sekitar cluster center. Untuk keperluan tersebut, di samping nilai keanggotaan dari data terhadap cluster, setiap data juga mempunyai nilai weight yang digunakan untuk meng-harmoni-kan pengaruh masing-masing data dalam pemodelan. Adapun objective function yang digunakan dalam metode ini adalah sebagai berikut: J (V) = SUM (k=1 to N) (c / (SUM (i=1 to c) (1/ (x_k- v_i)^p))) dimana: V : Matriks centroid/rata-rata masing-masing cluster N : Jumlah data c : Jumlah cluster v_i : Nilai centroid cluster ke-i p : suatu input parameter yang besarnya lebih dari atau sama dengan 2 Nilai membership function u_ik dan weight w_k dihitung dengan rumus sebagai berikut: u_ik = SUM (j=1 to c) ((x_k \u2013 v_i)/(x_k \u2013 v_j))^(-p-2) w_k = SUM (j=1 to c) (x_k \u2013 v_j)^(-p-2) / (SUM (j=1 to c) (x_k \u2013 v_j)^(-p))^2 Referensi: G. Hamerly and C. Elkan (2002). Altenatives to the k-means algorithm that find better clusterings . In Proceedings of the 11th International Conference on Information and Knowledge Management. pp. 600-607. Kernel K-means Variasi untuk sekumpulan data yang \u2018dianggap\u2019 terkelompok secara non-linear. K-means yang standar umumnya digunakan untuk mengelompokkan data yang secara umum datanya dipisahkan secara linear. Kalau data \u2018dianggap\u2019 terkelompok secara non-linear, k-means perlu dimodifikasi untuk dapat mengakomodasi ke-non-linear-an tersebut. Adapun metode yang diimplementasikan di dalam menyelesaikan permasalahan ini adalah dengan mengadopsi Kernel Trick dalam proses pengelompokan yang dilakukan. Perlu diketahui di sini, untuk bisa menerapkan Kernel Trick, data perlu untuk dipetakan terlebih dahulu ke bentuk data dengan dimensi yang lain, yang umumnya jumlah dimensinya lebih tinggi dengan fungsi THETA(x), yang artinya data x dipetakan dari dimensi awal ke dimensi yang lain (umumnya dimensi yang lebih tinggi). Adapun objective function yang digunakan untuk Kernel K-Means adalah: J (U, V) = SUM (k=1 to N) SUM (i=1 to c) (a_ik * (THETA(x_k), v_i)^2) dimana: U : Matriks keanggotaan data ke masing-masing cluster yang berisikan nilai 0 dan 1 V : Matriks centroid/rata-rata masing-masing cluster N : Jumlah data c : Jumlah cluster a_ik : Keanggotaan data ke-k ke cluster ke-i v_i : Nilai centroid cluster ke-i Rumus menghitung rata-rata/centroid: v_ij = SUM (k=0 to N_i) THETA (x_kj) / N_i yang tentunya tidak bisa dihitung, karena kita tidak bisa mengetahui nilai THETA (x_kj) secara langsung. Hal ini bisa diakali, dengan langsung menentukan nilai a_ik (yang nilainya adalah 1 atau 0), dimana a_ik bernilai 1 untuk data yang mempunyai jarak terdekat dengan centroid dan 0 untuk yang lainnya. Adapun jarak antara data dengan centroid dihitung dengan rumus berikut ini: (THETA(x_l),v_i)^2 = SUM (l=0 to N_i) THETA(x_lj) THETA(x_lj) \u2013 2 SUM (k,l=0 to N_i) THETA (x_lj) THETA (x_kj)/ N_i + SUM (k=0 to N_i) THETA (x_kj) THETA (x_kj)/ N_i Disini fungsi kernel disubstitusikan, sehingga jarak antara data dengan centroid dapat dihitung dengan rumus berikut ini: (THETA(x_l),v_i)^2 = SUM (l=0 to N_i) K(x_lj,x_lj) \u2013 2*SUM (k,l=0 to N_i) K (x_lj,x_kj)/ N_i + SUM (k=0 to N_i) K (x_kj,x_kj)/ N_i Data di-assign ke dalam kelompok yang jarak antara centroid dan data tersebut diminimalkan. Prosedur yang digunakan tetap sama dengan prosedur yang diterapkan pada standar k-means. Referensi M Girolami (2002). Mercer kernel-based clustering in feature space. Neural Networks, IEEE Transactions on, Vol. 13, No. 3., pp. 780-784. Inderjit S Dhillon, Yuqiang Guan, Brian Kulis (2004).Kernel k-means: spectral clustering and normalized cuts. pp. 551-556 K-Modes Variasi dalam hal data yang dianalisa bukan continuous, tapi categorical. Untuk data categorical, k-means tidak bisa digunakan karena data categorical tidak bisa dicari nilai means (rata-rata)-nya. Untuk keperluan tersebut K-Modes dapat digunakan sebagai gantinya. Adapun algoritma yang digunakan sama dengan k-means dengan beberapa modifikasi sebagai berikut: Step 1. Tentukan jumlah cluster Step 2. Alokasikan data ke dalam cluster secara random Step 3. Hitung modes dari data yang ada di masing-masing cluster. Step 4. Alokasikan masing-masing data ke cluster terdekat menggunakan Hemming Distance Step 5. Kembali ke Step 3, apabila masih ada data yang berpindah cluster atau apabila perubahan nilai modes atau apabila perubahan nilai pada objective function yang digunakan, di atas nilai threshold yang ditentukan Objective function yang digunakan k-modes adalah: J (A, M) = SUM (k=1 to N) SUM (i=1 to c) (a_ik * D(x_k, m_i)) dimana: A : Matriks keanggotaan data ke masing-masing cluster yang berisikan nilai 0 dan 1 M : Matriks modes masing-masing cluster N : Jumlah data c : Jumlah cluster a_ik : Keanggotaan data ke-k ke cluster ke-i x_k : data ke-k m_i : Nilai modes cluster ke-i D(x_k, m_i) : Hemming Distance antara data x dan modes m Referensi: Chaturvedi, A.D., Green, P.E. and Carroll, J.D. (2001). K-Modes Clustering. Journal of Classification, 18, 35-56.","title":"K-Means Clustering"},{"location":"authors-notes/","text":"Author's notes Hi, I'm Martin ( @squidfunk ) I'm a freelance polyglot software engineer and entrepreneur from Cologne, Germany with more than 12 years of experience in full-stack web development and system programming. If you're interested in my projects, please see my CV . Why another theme? Some time ago I wanted to release a project to the open, but it was in need of user documentation. I checked out the available tools and stuck with MkDocs, because it was so simple and easy to use. However, none of the available themes convinced me. I wanted to build something that was usable on all screen sizes from the ground up, something beautiful and practical at the same time. Google's Material Design appeared to be the perfect fit and this something became Material, a Material Design theme for MkDocs.","title":"Author's notes"},{"location":"authors-notes/#authors-notes","text":"","title":"Author's notes"},{"location":"authors-notes/#hi-im-martin-squidfunk","text":"I'm a freelance polyglot software engineer and entrepreneur from Cologne, Germany with more than 12 years of experience in full-stack web development and system programming. If you're interested in my projects, please see my CV .","title":"Hi, I'm Martin (@squidfunk)"},{"location":"authors-notes/#why-another-theme","text":"Some time ago I wanted to release a project to the open, but it was in need of user documentation. I checked out the available tools and stuck with MkDocs, because it was so simple and easy to use. However, none of the available themes convinced me. I wanted to build something that was usable on all screen sizes from the ground up, something beautiful and practical at the same time. Google's Material Design appeared to be the perfect fit and this something became Material, a Material Design theme for MkDocs.","title":"Why another theme?"},{"location":"compliance/","text":"Decision Tree # Run this program on your local python # interpreter, provided you have installed # the required libraries. # Importing the required packages import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn.metrics import classification_report # Function importing Dataset def importdata(): balance_data = pd.read_csv(\"part_1_data.csv\", sep= ',', header = None) # Printing the dataswet shape print (\"Dataset Lenght: \", len(balance_data)) print (\"Dataset Shape: \", balance_data.shape) # Printing the dataset obseravtions print('dataset :') print (balance_data.head()) return balance_data # Function to split the dataset def splitdataset(balance_data): # Seperating the target variable X = balance_data.values[:, 1:5] Y = balance_data.values[:, 0] # Spliting the dataset into train and test X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100) return X, Y, X_train, X_test, y_train, y_test # Function to perform training with giniIndex. def train_using_gini(X_train, X_test, y_train): # Creating the classifier object clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5) # Performing training clf_gini.fit(X_train, y_train) return clf_gini # Function to perform training with entropy. def tarin_using_entropy(X_train, X_test, y_train): # Decision tree with entropy clf_entropy = DecisionTreeClassifier( criterion = \"entropy\", random_state = 100, max_depth = 3, min_samples_leaf = 5) # Performing training clf_entropy.fit(X_train, y_train) return clf_entropy # Function to make predictions def prediction(X_test, clf_object): # Predicton on test with giniIndex y_pred = clf_object.predict(X_test) print(\"Predicted values:\") print(y_pred) return y_pred # Function to calculate accuracy def cal_accuracy(y_test, y_pred): print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100) print(\"Report : \", classification_report(y_test, y_pred)) # Driver code def main(): # Building Phase data = importdata() X, Y, X_train, X_test, y_train, y_test = splitdataset(data) clf_gini = train_using_gini(X_train, X_test, y_train) clf_entropy = tarin_using_entropy(X_train, X_test, y_train) # Operational Phase print(\"Results Using Gini Index:\") # Prediction using gini y_pred_gini = prediction(X_test, clf_gini) cal_accuracy(y_test, y_pred_gini) print(\"Results Using Entropy:\") # Prediction using entropy y_pred_entropy = prediction(X_test, clf_entropy) cal_accuracy(y_test, y_pred_entropy) # Calling main function if __name__==\"__main__\": main() Hasil dari Program : Dataset Lenght: 491 Dataset Shape: (491, 5) dataset : 0 999000 1960 1000 999 0 0 2750000 2006 1418 1939 1 0 1350000 1900 2150 628 2 0 629000 1903 500 1258 3 0 439000 1930 500 878 4 0 439000 1930 500 878 Results Using Gini Index: Predicted values: [0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0] Confusion Matrix: [[51 21] [ 8 68]] Accuracy : 80.4054054054054 Report : precision recall f1-score support 0 0.86 0.71 0.78 72 1 0.76 0.89 0.82 76 micro avg 0.80 0.80 0.80 148 macro avg 0.81 0.80 0.80 148 weighted avg 0.81 0.80 0.80 148 Results Using Entropy: Predicted values: [0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0] Confusion Matrix: [[36 36] [ 5 71]] Accuracy : 72.2972972972973 Report : precision recall f1-score support 0 0.88 0.50 0.64 72 1 0.66 0.93 0.78 76 micro avg 0.72 0.72 0.72 148 macro avg 0.77 0.72 0.71 148 weighted avg 0.77 0.72 0.71 148 Process finished with exit code 0","title":"Implemantasi Decision Tree"},{"location":"compliance/#decision-tree","text":"# Run this program on your local python # interpreter, provided you have installed # the required libraries. # Importing the required packages import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn.metrics import classification_report # Function importing Dataset def importdata(): balance_data = pd.read_csv(\"part_1_data.csv\", sep= ',', header = None) # Printing the dataswet shape print (\"Dataset Lenght: \", len(balance_data)) print (\"Dataset Shape: \", balance_data.shape) # Printing the dataset obseravtions print('dataset :') print (balance_data.head()) return balance_data # Function to split the dataset def splitdataset(balance_data): # Seperating the target variable X = balance_data.values[:, 1:5] Y = balance_data.values[:, 0] # Spliting the dataset into train and test X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100) return X, Y, X_train, X_test, y_train, y_test # Function to perform training with giniIndex. def train_using_gini(X_train, X_test, y_train): # Creating the classifier object clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5) # Performing training clf_gini.fit(X_train, y_train) return clf_gini # Function to perform training with entropy. def tarin_using_entropy(X_train, X_test, y_train): # Decision tree with entropy clf_entropy = DecisionTreeClassifier( criterion = \"entropy\", random_state = 100, max_depth = 3, min_samples_leaf = 5) # Performing training clf_entropy.fit(X_train, y_train) return clf_entropy # Function to make predictions def prediction(X_test, clf_object): # Predicton on test with giniIndex y_pred = clf_object.predict(X_test) print(\"Predicted values:\") print(y_pred) return y_pred # Function to calculate accuracy def cal_accuracy(y_test, y_pred): print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100) print(\"Report : \", classification_report(y_test, y_pred)) # Driver code def main(): # Building Phase data = importdata() X, Y, X_train, X_test, y_train, y_test = splitdataset(data) clf_gini = train_using_gini(X_train, X_test, y_train) clf_entropy = tarin_using_entropy(X_train, X_test, y_train) # Operational Phase print(\"Results Using Gini Index:\") # Prediction using gini y_pred_gini = prediction(X_test, clf_gini) cal_accuracy(y_test, y_pred_gini) print(\"Results Using Entropy:\") # Prediction using entropy y_pred_entropy = prediction(X_test, clf_entropy) cal_accuracy(y_test, y_pred_entropy) # Calling main function if __name__==\"__main__\": main() Hasil dari Program : Dataset Lenght: 491 Dataset Shape: (491, 5) dataset : 0 999000 1960 1000 999 0 0 2750000 2006 1418 1939 1 0 1350000 1900 2150 628 2 0 629000 1903 500 1258 3 0 439000 1930 500 878 4 0 439000 1930 500 878 Results Using Gini Index: Predicted values: [0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0] Confusion Matrix: [[51 21] [ 8 68]] Accuracy : 80.4054054054054 Report : precision recall f1-score support 0 0.86 0.71 0.78 72 1 0.76 0.89 0.82 76 micro avg 0.80 0.80 0.80 148 macro avg 0.81 0.80 0.80 148 weighted avg 0.81 0.80 0.80 148 Results Using Entropy: Predicted values: [0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0] Confusion Matrix: [[36 36] [ 5 71]] Accuracy : 72.2972972972973 Report : precision recall f1-score support 0 0.88 0.50 0.64 72 1 0.66 0.93 0.78 76 micro avg 0.72 0.72 0.72 148 macro avg 0.77 0.72 0.71 148 weighted avg 0.77 0.72 0.71 148 Process finished with exit code 0","title":"Decision Tree"},{"location":"contributing/","text":"../CONTRIBUTING.md","title":"Contributing"},{"location":"customization/","text":"K-Nearest Neighbor Algoritme k-nearest neighbor (k-NN atau KNN) adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. Data pembelajaran diproyeksikan ke ruang berdimensi banyak, dimana masing-masing dimensi merepresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi data pembelajaran. Sebuah titik pada ruang ini ditandai kelas c jika kelas c merupakan klasifikasi yang paling banyak ditemui pada k buah tetangga terdekat titk tersebut. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Euclidean. Pada fase pembelajaran, algoritme ini hanya melakukan penyimpanan vektor-vektor fitur dan klasifikasi dari data pembelajaran. Pada fase klasifikasi, fitur-fitur yang sama dihitung untuk data test (yang klasifikasinya tidak diketahui). Jarak dari vektor yang baru ini terhadap seluruh vektor data pembelajaran dihitung, dan sejumlah k buah yang paling dekat diambil. Titik yang baru klasifikasinya diprediksikan termasuk pada klasifikasi terbanyak dari titik-titik tersebut. Nilai k yang terbaik untuk algoritme ini tergantung pada data; secara umumnya, nilai k yang tinggi akan mengurangi efek noise pada klasifikasi, tetapi membuat batasan antara setiap klasifikasi menjadi lebih kabur. Nilai k yang bagus dapat dipilih dengan optimasi parameter, misalnya dengan menggunakan cross-validation. Kasus khusus di mana klasifikasi diprediksikan berdasarkan data pembelajaran yang paling dekat (dengan kata lain, k = 1) disebut algoritme nearest neighbor . Ketepatan algoritme k-NN ini sangat dipengaruhi oleh ada atau tidaknya fitur-fitur yang tidak relevan, atau jika bobot fitur tersebut tidak setara dengan relevansinya terhadap klasifikasi. Riset terhadap algoritme ini sebagian besar membahas bagaimana memilih dan memberi bobot terhadap fitur, agar performa klasifikasi menjadi lebih baik. Terdapat beberapa jenis algoritme pencarian tetangga terdekat, diantaranya: \u00b7 Linear scan \u00b7 Pohon kd \u00b7 Pohon Balltree \u00b7 Pohon metrik \u00b7 Locally-sensitive hashing (LSH) Algoritme k-NN ini memiliki konsistensi yang kuat. Ketika jumlah data mendekati tak hingga, algoritme ini menjamin error rate yang tidak lebih dari dua kali Bayes error rate ( error rate minimum untuk distribusi data tertentu).","title":"Apa itu K-Nearest Neighbor ?"},{"location":"getting-started/","text":"Langkah K-Means Clustering Menentukan secara acak K titik data sebagai pusat cluster yaitu disebut centroid. Menggunakan 3 centroid, yaitu individu 2,6,3. . Menghitung jarak x ke masing-masing pusat cluster. Penyelesaian di Microsoft Excel dengan rumus sebagai berikut: = SQRT((Ki - Xi)^2+ (Kj \u2013 Xj)^2+.......+(Kn\u2013 Xn)^2) Keterangan: K= Cluster X= Objek Selanjutnya masukkan x anggota centroid tertentu yang memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip dengan pusat cluster (centroid). Lalu tandai masing-masing x yang masuk ke cluster tertentu seperti dalam tabel berikut: Sehingga, di dapatkan tiga cluster dengan anggota pada individu: {1,2}, {4,5,6}.{3,7} Lalu menghitung rata-rata dari anggota cluster. Penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: =1/n*SUM( Xi + Xj+........+ Xn) Keterangan: n = Jumlah anggota cluster X = Anggota cluster \u200b Sehingga didapatkan tabel rata-rata sebagai berikut: Selanjutnya hasil perhitungan rata-rata tersebut dipergunakan untuk menghitung centroid baru, dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: Keterangan: \u200b x = rata-rata anggota cluster \u200b X = Objek Selanjutnya masukkan x anggota centroid tertentu yang memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip. Lalu tandai masing-masing x yang masuk ke cluster tertentu seperti dalam tabel berikut: Sehingga, Kita dapatkan tiga cluster dengan anggotanya pada individu: {1,2}, {4,5,6,7} Ulangai langkah 2 dan 3 sampai tidak ada dari anggota setiap cluster berubah tempat kelompoknya. Dan dikarenakan dalam contoh ini mengahasilkan anggota cluster yang tidak berubah tempat kelompoknya maka tidak ada pengulangan untuk langkah 2 dan 3. Menentukan Jumlah Cluter V adility = intra/inter Keterangan: Jarak Intra cluster = \u2211 (i=1)^k\u2592\u2211 (x\u2208c_i)\u2592\u3016(x-z_i )^2 \u3017 Jarak Inter-cluster = min (zi \u2013zj)2 i=1,2,3\u2026K-1 J=i+1,\u2026K \u200b Implementasi pada Microsoft Excel sebagai berikut: Menghitung Silhoutte Hitung rata-rata jarak objek dengan semua objek lain yang berada di dalam satu cluster dengan persamaan : Dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: Keterangan : \u200b X = Objek Hitung rata-rata jarak objek dengan semua objek lain yang berada pada cluster lain, dengan persamaan : Penyelesaian menghitung jarak menggunakan Microsoft Excel dengan rumus sebagai berikut: = SQRT((Ki - Xi)^2+ (Kj \u2013 Xj)^2+.......+(Kn\u2013 Xn)^2) Keterangan: \u200b K = Anggota Cluster \u200b X = Objek Selanjutnya menghitung rata-rata jarak menggunakan Microsoft Excel dengan rumus sebagai berikut: =1/n*SUM( Di + Dj+........+ Dn) Keterangan: D = Jarak n = Banyaknya jarak Setelah nilai untuk mendapat nilai bi maka cari nilai rata-rata antar cluster yang paling minimum Hitung nilai silhouette coefficient, dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: \u200b Si = 1- (ai /bi) Hasil Implementasi Pada Excel Shilhoutte Cluster 1 Hasil nilai silhouette coefficient adalah mendekati 1 maka pengelompokan data didalam cluster 1 bersifat baik Shilhoutte Cluster 2 Hasil nilai silhouette coefficient adalah mendekati -1 maka pengelompokan data didalam cluster 1 bersifat kurang baik. Shilhoutte Cluster 3 Hasil nilai silhouette coefficient adalah mendekati -1 maka pengelompokan data didalam cluster 1 bersifat kurang baik.","title":"Implemantasi K-Mean clustering"},{"location":"license/","text":"License MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"release-notes/","text":"Materi KNN Algoritme k-nearest neighbor (k-NN atau KNN) adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. Data pembelajaran diproyeksikan ke ruang berdimensi banyak, dimana masing-masing dimensi merepresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi data pembelajaran. Sebuah titik pada ruang ini ditandai kelas c jika kelas c merupakan klasifikasi yang paling banyak ditemui pada k buah tetangga terdekat titk tersebut. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Euclidean. Pada fase pembelajaran, algoritme ini hanya melakukan penyimpanan vektor-vektor fitur dan klasifikasi dari data pembelajaran. Pada fase klasifikasi, fitur-fitur yang sama dihitung untuk data test (yang klasifikasinya tidak diketahui). Jarak dari vektor yang baru ini terhadap seluruh vektor data pembelajaran dihitung, dan sejumlah k buah yang paling dekat diambil. Titik yang baru klasifikasinya diprediksikan termasuk pada klasifikasi terbanyak dari titik-titik tersebut. Nilai k yang terbaik untuk algoritme ini tergantung pada data; secara umumnya, nilai k yang tinggi akan mengurangi efek noise pada klasifikasi, tetapi membuat batasan antara setiap klasifikasi menjadi lebih kabur. Nilai k yang bagus dapat dipilih dengan optimasi parameter, misalnya dengan menggunakan cross-validation. Kasus khusus di mana klasifikasi diprediksikan berdasarkan data pembelajaran yang paling dekat (dengan kata lain, k = 1) disebut algoritme nearest neighbor . Ketepatan algoritme k-NN ini sangat dipengaruhi oleh ada atau tidaknya fitur-fitur yang tidak relevan, atau jika bobot fitur tersebut tidak setara dengan relevansinya terhadap klasifikasi. Riset terhadap algoritme ini sebagian besar membahas bagaimana memilih dan memberi bobot terhadap fitur, agar performa klasifikasi menjadi lebih baik. Terdapat beberapa jenis algoritme pencarian tetangga terdekat, diantaranya: Linear scan Pohon kd Pohon Balltree Pohon metrik Locally-sensitive hashing (LSH) Algoritme k-NN ini memiliki konsistensi yang kuat. Ketika jumlah data mendekati tak hingga, algoritme ini menjamin error rate yang tidak lebih dari dua kali Bayes error rate ( error rate minimum untuk distribusi data tertentu). import numpy as np from sklearn import preprocessing, cross_validation, neighbors import pandas as pd from numpy import sum def main(): df = pd.read_csv('iris_flower.txt') #df.replace('?', -99999, inplace=True) X = np.array(df.drop(['class'], 1)) Y = np.array(df['class']) count = 0 accuracy = [] while count<=10: X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=0.2) clf = neighbors.KNeighborsClassifier() clf.fit(X_train, Y_train) accuracy.append(clf.score(X_test, Y_test)) count+=1 #endwhile avg_accuracy = sum(np.array(accuracy))/len(accuracy) print(avg_accuracy) # testing the flower class type with our custom data flower_test = np.array([[6.5,2.5,2.9,0.7], [4.2,3.1,5.3,2.6], [5.1,4.6,9.5,1.4]]) flower_test = flower_test.reshape(len(flower_test), -1) predict = clf.predict(flower_test) print(predict) return #enddef if __name__ == '__main__': main()","title":"Implemantasi K-Nearest Neighbor with Python"},{"location":"release-notes/#materi-knn","text":"Algoritme k-nearest neighbor (k-NN atau KNN) adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. Data pembelajaran diproyeksikan ke ruang berdimensi banyak, dimana masing-masing dimensi merepresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi data pembelajaran. Sebuah titik pada ruang ini ditandai kelas c jika kelas c merupakan klasifikasi yang paling banyak ditemui pada k buah tetangga terdekat titk tersebut. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Euclidean. Pada fase pembelajaran, algoritme ini hanya melakukan penyimpanan vektor-vektor fitur dan klasifikasi dari data pembelajaran. Pada fase klasifikasi, fitur-fitur yang sama dihitung untuk data test (yang klasifikasinya tidak diketahui). Jarak dari vektor yang baru ini terhadap seluruh vektor data pembelajaran dihitung, dan sejumlah k buah yang paling dekat diambil. Titik yang baru klasifikasinya diprediksikan termasuk pada klasifikasi terbanyak dari titik-titik tersebut. Nilai k yang terbaik untuk algoritme ini tergantung pada data; secara umumnya, nilai k yang tinggi akan mengurangi efek noise pada klasifikasi, tetapi membuat batasan antara setiap klasifikasi menjadi lebih kabur. Nilai k yang bagus dapat dipilih dengan optimasi parameter, misalnya dengan menggunakan cross-validation. Kasus khusus di mana klasifikasi diprediksikan berdasarkan data pembelajaran yang paling dekat (dengan kata lain, k = 1) disebut algoritme nearest neighbor . Ketepatan algoritme k-NN ini sangat dipengaruhi oleh ada atau tidaknya fitur-fitur yang tidak relevan, atau jika bobot fitur tersebut tidak setara dengan relevansinya terhadap klasifikasi. Riset terhadap algoritme ini sebagian besar membahas bagaimana memilih dan memberi bobot terhadap fitur, agar performa klasifikasi menjadi lebih baik. Terdapat beberapa jenis algoritme pencarian tetangga terdekat, diantaranya: Linear scan Pohon kd Pohon Balltree Pohon metrik Locally-sensitive hashing (LSH) Algoritme k-NN ini memiliki konsistensi yang kuat. Ketika jumlah data mendekati tak hingga, algoritme ini menjamin error rate yang tidak lebih dari dua kali Bayes error rate ( error rate minimum untuk distribusi data tertentu). import numpy as np from sklearn import preprocessing, cross_validation, neighbors import pandas as pd from numpy import sum def main(): df = pd.read_csv('iris_flower.txt') #df.replace('?', -99999, inplace=True) X = np.array(df.drop(['class'], 1)) Y = np.array(df['class']) count = 0 accuracy = [] while count<=10: X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=0.2) clf = neighbors.KNeighborsClassifier() clf.fit(X_train, Y_train) accuracy.append(clf.score(X_test, Y_test)) count+=1 #endwhile avg_accuracy = sum(np.array(accuracy))/len(accuracy) print(avg_accuracy) # testing the flower class type with our custom data flower_test = np.array([[6.5,2.5,2.9,0.7], [4.2,3.1,5.3,2.6], [5.1,4.6,9.5,1.4]]) flower_test = flower_test.reshape(len(flower_test), -1) predict = clf.predict(flower_test) print(predict) return #enddef if __name__ == '__main__': main()","title":"Materi KNN"},{"location":"specimen/","text":"Decision Tree Decision Tree (Pohon Keputusan) adalah pohon dimana setiap cabangnyamenunjukkan pilihan diantara sejumlah alternatif pilihan yang ada, dan setiapdaunnya menunjukkan keputusan yang dipilih.Decision tree biasa digunakan untuk mendapatkan informasi untuk tujuanpengambilan sebuah keputusan. Decision tree dimulai dengan sebuah root node(titik awal) yang dipakai oleh user untuk mengambil tindakan. Dari node root ini,user memecahnya sesuai dengan algoritma decision tree. Hasil akhirnya adalahsebuah decision tree dengan setiap cabangnya menunjukkan kemungkinansekenario dari keputusan yang diambil serta hasilnya Contoh Pemanfaatan Decision Tree Diagnosa beberapa penyakit seperti kanker, hipertensi, stroke. Menentukan apakah dengan kondisi yang ada layak untuk bermaintenis atau tidak \u200b Menentukan apakah sebuah investasi bisnis layak dilakukan atau tidak \u200b Pemilihan pegawai teladan sesuai dengan kriteria tertentu Deteksi gangguan pada komputer atau jaringan komputer \u200b Pemilihan produk seperti rumah, kendaraan dan lain lain","title":"Apa itu Decision Tree ?"},{"location":"specimen/#decision-tree","text":"Decision Tree (Pohon Keputusan) adalah pohon dimana setiap cabangnyamenunjukkan pilihan diantara sejumlah alternatif pilihan yang ada, dan setiapdaunnya menunjukkan keputusan yang dipilih.Decision tree biasa digunakan untuk mendapatkan informasi untuk tujuanpengambilan sebuah keputusan. Decision tree dimulai dengan sebuah root node(titik awal) yang dipakai oleh user untuk mengambil tindakan. Dari node root ini,user memecahnya sesuai dengan algoritma decision tree. Hasil akhirnya adalahsebuah decision tree dengan setiap cabangnya menunjukkan kemungkinansekenario dari keputusan yang diambil serta hasilnya Contoh Pemanfaatan Decision Tree Diagnosa beberapa penyakit seperti kanker, hipertensi, stroke. Menentukan apakah dengan kondisi yang ada layak untuk bermaintenis atau tidak \u200b Menentukan apakah sebuah investasi bisnis layak dilakukan atau tidak \u200b Pemilihan pegawai teladan sesuai dengan kriteria tertentu Deteksi gangguan pada komputer atau jaringan komputer \u200b Pemilihan produk seperti rumah, kendaraan dan lain lain","title":"Decision Tree"},{"location":"extensions/admonition/","text":"Admonition Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - admonition Usage Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Changing the title By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Removing the title Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Embedded code blocks Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` mysql SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Collapsible blocks The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default. Types Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note . Note Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso Abstract Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr Info Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo Tip Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important Success Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done Question Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq Warning Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention Failure Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing Danger Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error Bug Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug Example Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet Quote Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Admonition"},{"location":"extensions/admonition/#admonition","text":"Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings.","title":"Admonition"},{"location":"extensions/admonition/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - admonition","title":"Installation"},{"location":"extensions/admonition/#usage","text":"Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Usage"},{"location":"extensions/admonition/#changing-the-title","text":"By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Changing the title"},{"location":"extensions/admonition/#removing-the-title","text":"Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Removing the title"},{"location":"extensions/admonition/#embedded-code-blocks","text":"Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` mysql SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim.","title":"Embedded code blocks"},{"location":"extensions/admonition/#collapsible-blocks","text":"The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default.","title":"Collapsible blocks"},{"location":"extensions/admonition/#types","text":"Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note .","title":"Types"},{"location":"extensions/admonition/#note","text":"Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso","title":"Note"},{"location":"extensions/admonition/#abstract","text":"Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr","title":"Abstract"},{"location":"extensions/admonition/#info","text":"Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo","title":"Info"},{"location":"extensions/admonition/#tip","text":"Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important","title":"Tip"},{"location":"extensions/admonition/#success","text":"Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done","title":"Success"},{"location":"extensions/admonition/#question","text":"Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq","title":"Question"},{"location":"extensions/admonition/#warning","text":"Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention","title":"Warning"},{"location":"extensions/admonition/#failure","text":"Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing","title":"Failure"},{"location":"extensions/admonition/#danger","text":"Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error","title":"Danger"},{"location":"extensions/admonition/#bug","text":"Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug","title":"Bug"},{"location":"extensions/admonition/#example","text":"Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet","title":"Example"},{"location":"extensions/admonition/#quote","text":"Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Quote"},{"location":"extensions/codehilite/","text":"CodeHilite CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. !!! failure \"Syntax highlighting not working?\" Please ensure that [Pygments][2] is installed. See the next section for further directions on how to set up Pygments or use the official [Docker image][3] with all dependencies pre-installed. Installation CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions: - codehilite Usage Specifying the language The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways. via Markdown syntax recommended In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf via Shebang Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf via three colons If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: :::python import tensorflow as tf Adding line numbers Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions: - codehilite: linenums: true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] Grouping code blocks The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: ``` bash tab=\"Bash\" !/bin/bash echo \"Hello world!\" ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` c++ tab=\"C++\" include int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } Highlighting specific lines Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] Supported languages excerpt CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt. Bash #!/bin/bash for OPT in \"$@\" do case \"$OPT\" in '-f' ) canonicalize=1 ;; '-n' ) switchlf=\"-n\" ;; esac done # readlink -f function __readlink_f { target=\"$1\" while test -n \"$target\"; do filepath=\"$target\" cd `dirname \"$filepath\"` target=`readlink \"$filepath\"` done /bin/echo $switchlf `pwd -P`/`basename \"$filepath\"` } if [ ! \"$canonicalize\" ]; then readlink $switchlf \"$@\" else for file in \"$@\" do case \"$file\" in -* ) ;; * ) __readlink_f \"$file\" ;; esac done fi exit $? C extern size_t pb_varint_scan(const uint8_t data[], size_t left) { assert(data && left); left = left > 10 ? 10 : left; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map[] = { 0x0000, 0x0001, 0x0003, 0x0007, 0x000F, 0x001F, 0x003F, 0x007F, 0x00FF, 0x01FF, 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128((const __m128i *)data); __m128i high = _mm_set1_epi8(0x80); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8(_mm_and_si128(temp, high)); mask = (mask & mask_map[left]) ^ mask_map[left]; /* Count trailing zeroes */ return mask ? __builtin_ctz(mask) + 1 : 0; #else /* Linear scan */ size_t size = 0; while (data[size++] & 0x80) if (!--left) return 0; return size; #endif /* __SSE2__ */ } C++ Extension:: Extension(const Descriptor *descriptor, const Descriptor *scope) : descriptor_(descriptor), scope_(scope) { /* Extract full name for signature */ variables_[\"signature\"] = descriptor_->full_name(); /* Prepare message symbol */ variables_[\"message\"] = StringReplace( variables_[\"signature\"], \".\", \"_\", true); LowerString(&(variables_[\"message\"])); /* Suffix scope to identifiers, if given */ string suffix (\"\"); if (scope_) { suffix = scope_->full_name(); /* Check if the base and extension types are in the same package */ if (!scope_->file()->package().compare(descriptor_->file()->package())) suffix = StripPrefixString(suffix, scope_->file()->package() + \".\"); /* Append to signature */ variables_[\"signature\"] += \".[\" + suffix +\"]\"; suffix = \"_\" + suffix; } /* Prepare extension symbol */ variables_[\"extension\"] = StringReplace( suffix, \".\", \"_\", true); LowerString(&(variables_[\"extension\"])); } C# public static void Send( Socket socket, byte[] buffer, int offset, int size, int timeout) { int startTickCount = Environment.TickCount; int sent = 0; do { if (Environment.TickCount > startTickCount + timeout) throw new Exception(\"Timeout.\"); try { sent += socket.Send(buffer, offset + sent, size - sent, SocketFlags.None); } catch (SocketException ex) { if (ex.SocketErrorCode == SocketError.WouldBlock || ex.SocketErrorCode == SocketError.IOPending || ex.SocketErrorCode == SocketError.NoBufferSpaceAvailable) { /* Socket buffer is probably full, wait and try again */ Thread.Sleep(30); } else { throw ex; } } } while (sent < size); } Clojure (clojure-version) (defn partition-when [f] (fn [rf] (let [a (java.util.ArrayList.) fval (volatile! false)] (fn ([] (rf)) ([result] (let [result (if (.isEmpty a) result (let [v (vec (.toArray a))] ;; Clear first (.clear a) (unreduced (rf result v))))] (rf result))) ([result input] (if-not (and (f input) @fval) (do (vreset! fval true) (.add a input) result) (let [v (vec (.toArray a))] (.clear a) (let [ret (rf result v)] (when-not (reduced? ret) (.add a input)) ret)))))))) (into [] (partition-when #(.startsWith % \">>\")) [\"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\"]) Diff Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js', Docker FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [\"x11vnc\", \"-forever\", \"-usepw\", \"-create\"] Elixir require Logger def accept(port) do {:ok, socket} = :gen_tcp.listen(port, [:binary, packet: :line, active: false, reuseaddr: true]) Logger.info \"Accepting connections on port #{port}\" loop_acceptor(socket) end defp loop_acceptor(socket) do {:ok, client} = :gen_tcp.accept(socket) serve(client) loop_acceptor(socket) end defp serve(socket) do socket |> read_line() |> write_line(socket) serve(socket) end defp read_line(socket) do {:ok, data} = :gen_tcp.recv(socket, 0) data end defp write_line(line, socket) do :gen_tcp.send(socket, line) end Erlang circular(Defs) -> [ { { Type, Base }, Fields } || { { Type, Base }, Fields } <- Defs, Type == msg, circular(Base, Defs) ]. circular(Base, Defs) -> Fields = proplists:get_value({ msg, Base }, Defs), circular(Defs, Fields, [Base]). circular(_Defs, [], _Path) -> false; circular(Defs, [Field | Fields], Path) -> case Field#field.type of { msg, Type } -> case lists:member(Type, Path) of false -> Children = proplists:get_value({ msg, Type }, Defs), case circular(Defs, Children, [Type | Path]) of false -> circular(Defs, Fields, Path); true -> true end; true -> Type == lists:last(Path) andalso (length(Path) == 1 orelse not is_tree(Path)) end; _ -> circular(Defs, Fields, Path) end. F# /// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [<Js>] getRectangles () : Async<Rectangle[]> = async { let req = XMLHttpRequest() req.Open(\"POST\", \"/get\", true) let! resp = req.AsyncSend() return JSON.parse(resp) } /// Repeatedly update rectangles after 0.5 sec let [<Js>] updateLoop () = async { while true do do! Async.Sleep(500) let! rects = getRectangles() cleanRectangles() rects |> Array.iter createRectangle } Go package main import \"fmt\" func counter(id int, channel chan int, closer bool) { for i := 0; i < 10000000; i++ { fmt.Println(\"process\", id,\" send\", i) channel <- 1 } if closer { close(channel ) } } func main() { channel := make(chan int) go counter(1, channel, false) go counter(2, channel, true) x := 0 // receiving data from channel for i := range channel { fmt.Println(\"receiving\") x += i } fmt.Println(x) } HTML <!doctype html> <html class=\"no-js\" lang=\"\"> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"> <title>HTML5 Boilerplate</title> <meta name=\"description\" content=\"\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <link rel=\"apple-touch-icon\" href=\"apple-touch-icon.png\"> <link rel=\"stylesheet\" href=\"css/normalize.css\"> <link rel=\"stylesheet\" href=\"css/main.css\"> <script src=\"js/vendor/modernizr-2.8.3.min.js\"></script> </head> <body> <p>Hello world! This is HTML5 Boilerplate.</p> </body> </html> Java import java.util.LinkedList; import java.lang.reflect.Array; public class UnsortedHashSet<E> { private static final double LOAD_FACTOR_LIMIT = 0.7; private int size; private LinkedList<E>[] con; public UnsortedHashSet() { con = (LinkedList<E>[])(new LinkedList[10]); } public boolean add(E obj) { int oldSize = size; int index = Math.abs(obj.hashCode()) % con.length; if (con[index] == null) con[index] = new LinkedList<E>(); if (!con[index].contains(obj)) { con[index].add(obj); size++; } if (1.0 * size / con.length > LOAD_FACTOR_LIMIT) resize(); return oldSize != size; } private void resize() { UnsortedHashSet<E> temp = new UnsortedHashSet<E>(); temp.con = (LinkedList<E>[])(new LinkedList[con.length * 2 + 1]); for (int i = 0; i < con.length; i++) { if (con[i] != null) for (E e : con[i]) temp.add(e); } con = temp.con; } public int size() { return size; } } JavaScript var Math = require('lib/math'); var _extends = function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; var e = exports.e = 2.71828182846; exports['default'] = function (x) { return Math.exp(x); }; module.exports = _extends(exports['default'], exports); JSON { \"name\": \"mkdocs-material\", \"version\": \"0.2.4\", \"description\": \"A Material Design theme for MkDocs\", \"homepage\": \"http://squidfunk.github.io/mkdocs-material/\", \"authors\": [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\": \"MIT\", \"main\": \"Gulpfile.js\", \"scripts\": { \"start\": \"./node_modules/.bin/gulp watch --mkdocs\", \"build\": \"./node_modules/.bin/gulp build --production\" } ... } Julia using MXNet mlp = @mx.chain mx.Variable(:data) => mx.FullyConnected(name=:fc1, num_hidden=128) => mx.Activation(name=:relu1, act_type=:relu) => mx.FullyConnected(name=:fc2, num_hidden=64) => mx.Activation(name=:relu2, act_type=:relu) => mx.FullyConnected(name=:fc3, num_hidden=10) => mx.SoftmaxOutput(name=:softmax) # data provider batch_size = 100 include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\")) train_provider, eval_provider = get_mnist_providers(batch_size) # setup model model = mx.FeedForward(mlp, context=mx.cpu()) # optimization algorithm optimizer = mx.SGD(lr=0.1, momentum=0.9) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider) Lua local ffi = require(\"ffi\") ffi.cdef[[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi.os == \"Windows\" then function sleep(s) ffi.C.Sleep(s*1000) end else function sleep(s) ffi.C.poll(nil, 0, s * 1000) end end for i = 1,160 do io.write(\".\"); io.flush() sleep(0.01) end io.write(\"\\n\") MySQL SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; PHP <?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route; use Symfony\\Component\\HttpFoundation\\Response; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction() { $number = mt_rand(0, 100); return new Response( '<html><body>Lucky number: '.$number.'</body></html>' ); } } Protocol Buffers syntax = \"proto2\"; package caffe; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [packed = true]; } message BlobProto { optional BlobShape shape = 7; repeated float data = 5 [packed = true]; repeated float diff = 6 [packed = true]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [default = 0]; optional int32 channels = 2 [default = 0]; optional int32 height = 3 [default = 0]; optional int32 width = 4 [default = 0]; } Python \"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_string('data_dir', '/tmp/data/', 'Directory for storing data') mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True) sess = tf.InteractiveSession() # Create the model x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b) Ruby require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError; end class MissingCallback < StandardError; end class InvalidState < StandardError; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, &block @finity ||= Machine.new self, options, &block end # Return the names of all registered states. def states @finity.states.map { |name, _| name } end # Return the names of all registered events. def events @finity.events.map { |name, _| name } end end # Inject methods into the including class upon inclusion. def self.included base base.extend ClassMethods end end XML <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"> <!-- This is a sample comment --> <childTag attribute=\"Quoted Value\" another-attribute='Single quoted value' a-third-attribute='123'> <withTextContent>Some text content</withTextContent> <withEntityContent>Some text content with &lt;entities&gt; and mentioning uint8_t and int32_t</withEntityContent> <otherTag attribute='Single quoted Value'/> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"CodeHilite"},{"location":"extensions/codehilite/#codehilite","text":"CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. !!! failure \"Syntax highlighting not working?\" Please ensure that [Pygments][2] is installed. See the next section for further directions on how to set up Pygments or use the official [Docker image][3] with all dependencies pre-installed.","title":"CodeHilite"},{"location":"extensions/codehilite/#installation","text":"CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions: - codehilite","title":"Installation"},{"location":"extensions/codehilite/#usage","text":"","title":"Usage"},{"location":"extensions/codehilite/#specifying-the-language","text":"The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways.","title":"Specifying the language"},{"location":"extensions/codehilite/#via-markdown-syntax-recommended","text":"In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf","title":"via Markdown syntax recommended"},{"location":"extensions/codehilite/#via-shebang","text":"Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf","title":"via Shebang"},{"location":"extensions/codehilite/#via-three-colons","text":"If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: :::python import tensorflow as tf","title":"via three colons"},{"location":"extensions/codehilite/#adding-line-numbers","text":"Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions: - codehilite: linenums: true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j]","title":"Adding line numbers"},{"location":"extensions/codehilite/#grouping-code-blocks","text":"The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: ``` bash tab=\"Bash\"","title":"Grouping code blocks"},{"location":"extensions/codehilite/#binbash","text":"echo \"Hello world!\" ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` c++ tab=\"C++\"","title":"!/bin/bash"},{"location":"extensions/codehilite/#include","text":"int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } }","title":"include "},{"location":"extensions/codehilite/#highlighting-specific-lines","text":"Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j]","title":"Highlighting specific lines"},{"location":"extensions/codehilite/#supported-languages-excerpt","text":"CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt.","title":"Supported languages excerpt"},{"location":"extensions/codehilite/#bash","text":"#!/bin/bash for OPT in \"$@\" do case \"$OPT\" in '-f' ) canonicalize=1 ;; '-n' ) switchlf=\"-n\" ;; esac done # readlink -f function __readlink_f { target=\"$1\" while test -n \"$target\"; do filepath=\"$target\" cd `dirname \"$filepath\"` target=`readlink \"$filepath\"` done /bin/echo $switchlf `pwd -P`/`basename \"$filepath\"` } if [ ! \"$canonicalize\" ]; then readlink $switchlf \"$@\" else for file in \"$@\" do case \"$file\" in -* ) ;; * ) __readlink_f \"$file\" ;; esac done fi exit $?","title":"Bash"},{"location":"extensions/codehilite/#c","text":"extern size_t pb_varint_scan(const uint8_t data[], size_t left) { assert(data && left); left = left > 10 ? 10 : left; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map[] = { 0x0000, 0x0001, 0x0003, 0x0007, 0x000F, 0x001F, 0x003F, 0x007F, 0x00FF, 0x01FF, 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128((const __m128i *)data); __m128i high = _mm_set1_epi8(0x80); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8(_mm_and_si128(temp, high)); mask = (mask & mask_map[left]) ^ mask_map[left]; /* Count trailing zeroes */ return mask ? __builtin_ctz(mask) + 1 : 0; #else /* Linear scan */ size_t size = 0; while (data[size++] & 0x80) if (!--left) return 0; return size; #endif /* __SSE2__ */ }","title":"C"},{"location":"extensions/codehilite/#c_1","text":"Extension:: Extension(const Descriptor *descriptor, const Descriptor *scope) : descriptor_(descriptor), scope_(scope) { /* Extract full name for signature */ variables_[\"signature\"] = descriptor_->full_name(); /* Prepare message symbol */ variables_[\"message\"] = StringReplace( variables_[\"signature\"], \".\", \"_\", true); LowerString(&(variables_[\"message\"])); /* Suffix scope to identifiers, if given */ string suffix (\"\"); if (scope_) { suffix = scope_->full_name(); /* Check if the base and extension types are in the same package */ if (!scope_->file()->package().compare(descriptor_->file()->package())) suffix = StripPrefixString(suffix, scope_->file()->package() + \".\"); /* Append to signature */ variables_[\"signature\"] += \".[\" + suffix +\"]\"; suffix = \"_\" + suffix; } /* Prepare extension symbol */ variables_[\"extension\"] = StringReplace( suffix, \".\", \"_\", true); LowerString(&(variables_[\"extension\"])); }","title":"C++"},{"location":"extensions/codehilite/#c_2","text":"public static void Send( Socket socket, byte[] buffer, int offset, int size, int timeout) { int startTickCount = Environment.TickCount; int sent = 0; do { if (Environment.TickCount > startTickCount + timeout) throw new Exception(\"Timeout.\"); try { sent += socket.Send(buffer, offset + sent, size - sent, SocketFlags.None); } catch (SocketException ex) { if (ex.SocketErrorCode == SocketError.WouldBlock || ex.SocketErrorCode == SocketError.IOPending || ex.SocketErrorCode == SocketError.NoBufferSpaceAvailable) { /* Socket buffer is probably full, wait and try again */ Thread.Sleep(30); } else { throw ex; } } } while (sent < size); }","title":"C&#35;"},{"location":"extensions/codehilite/#clojure","text":"(clojure-version) (defn partition-when [f] (fn [rf] (let [a (java.util.ArrayList.) fval (volatile! false)] (fn ([] (rf)) ([result] (let [result (if (.isEmpty a) result (let [v (vec (.toArray a))] ;; Clear first (.clear a) (unreduced (rf result v))))] (rf result))) ([result input] (if-not (and (f input) @fval) (do (vreset! fval true) (.add a input) result) (let [v (vec (.toArray a))] (.clear a) (let [ret (rf result v)] (when-not (reduced? ret) (.add a input)) ret)))))))) (into [] (partition-when #(.startsWith % \">>\")) [\"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\"])","title":"Clojure"},{"location":"extensions/codehilite/#diff","text":"Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js',","title":"Diff"},{"location":"extensions/codehilite/#docker","text":"FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [\"x11vnc\", \"-forever\", \"-usepw\", \"-create\"]","title":"Docker"},{"location":"extensions/codehilite/#elixir","text":"require Logger def accept(port) do {:ok, socket} = :gen_tcp.listen(port, [:binary, packet: :line, active: false, reuseaddr: true]) Logger.info \"Accepting connections on port #{port}\" loop_acceptor(socket) end defp loop_acceptor(socket) do {:ok, client} = :gen_tcp.accept(socket) serve(client) loop_acceptor(socket) end defp serve(socket) do socket |> read_line() |> write_line(socket) serve(socket) end defp read_line(socket) do {:ok, data} = :gen_tcp.recv(socket, 0) data end defp write_line(line, socket) do :gen_tcp.send(socket, line) end","title":"Elixir"},{"location":"extensions/codehilite/#erlang","text":"circular(Defs) -> [ { { Type, Base }, Fields } || { { Type, Base }, Fields } <- Defs, Type == msg, circular(Base, Defs) ]. circular(Base, Defs) -> Fields = proplists:get_value({ msg, Base }, Defs), circular(Defs, Fields, [Base]). circular(_Defs, [], _Path) -> false; circular(Defs, [Field | Fields], Path) -> case Field#field.type of { msg, Type } -> case lists:member(Type, Path) of false -> Children = proplists:get_value({ msg, Type }, Defs), case circular(Defs, Children, [Type | Path]) of false -> circular(Defs, Fields, Path); true -> true end; true -> Type == lists:last(Path) andalso (length(Path) == 1 orelse not is_tree(Path)) end; _ -> circular(Defs, Fields, Path) end.","title":"Erlang"},{"location":"extensions/codehilite/#f","text":"/// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [<Js>] getRectangles () : Async<Rectangle[]> = async { let req = XMLHttpRequest() req.Open(\"POST\", \"/get\", true) let! resp = req.AsyncSend() return JSON.parse(resp) } /// Repeatedly update rectangles after 0.5 sec let [<Js>] updateLoop () = async { while true do do! Async.Sleep(500) let! rects = getRectangles() cleanRectangles() rects |> Array.iter createRectangle }","title":"F&#35;"},{"location":"extensions/codehilite/#go","text":"package main import \"fmt\" func counter(id int, channel chan int, closer bool) { for i := 0; i < 10000000; i++ { fmt.Println(\"process\", id,\" send\", i) channel <- 1 } if closer { close(channel ) } } func main() { channel := make(chan int) go counter(1, channel, false) go counter(2, channel, true) x := 0 // receiving data from channel for i := range channel { fmt.Println(\"receiving\") x += i } fmt.Println(x) }","title":"Go"},{"location":"extensions/codehilite/#html","text":"<!doctype html> <html class=\"no-js\" lang=\"\"> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"> <title>HTML5 Boilerplate</title> <meta name=\"description\" content=\"\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <link rel=\"apple-touch-icon\" href=\"apple-touch-icon.png\"> <link rel=\"stylesheet\" href=\"css/normalize.css\"> <link rel=\"stylesheet\" href=\"css/main.css\"> <script src=\"js/vendor/modernizr-2.8.3.min.js\"></script> </head> <body> <p>Hello world! This is HTML5 Boilerplate.</p> </body> </html>","title":"HTML"},{"location":"extensions/codehilite/#java","text":"import java.util.LinkedList; import java.lang.reflect.Array; public class UnsortedHashSet<E> { private static final double LOAD_FACTOR_LIMIT = 0.7; private int size; private LinkedList<E>[] con; public UnsortedHashSet() { con = (LinkedList<E>[])(new LinkedList[10]); } public boolean add(E obj) { int oldSize = size; int index = Math.abs(obj.hashCode()) % con.length; if (con[index] == null) con[index] = new LinkedList<E>(); if (!con[index].contains(obj)) { con[index].add(obj); size++; } if (1.0 * size / con.length > LOAD_FACTOR_LIMIT) resize(); return oldSize != size; } private void resize() { UnsortedHashSet<E> temp = new UnsortedHashSet<E>(); temp.con = (LinkedList<E>[])(new LinkedList[con.length * 2 + 1]); for (int i = 0; i < con.length; i++) { if (con[i] != null) for (E e : con[i]) temp.add(e); } con = temp.con; } public int size() { return size; } }","title":"Java"},{"location":"extensions/codehilite/#javascript","text":"var Math = require('lib/math'); var _extends = function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; var e = exports.e = 2.71828182846; exports['default'] = function (x) { return Math.exp(x); }; module.exports = _extends(exports['default'], exports);","title":"JavaScript"},{"location":"extensions/codehilite/#json","text":"{ \"name\": \"mkdocs-material\", \"version\": \"0.2.4\", \"description\": \"A Material Design theme for MkDocs\", \"homepage\": \"http://squidfunk.github.io/mkdocs-material/\", \"authors\": [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\": \"MIT\", \"main\": \"Gulpfile.js\", \"scripts\": { \"start\": \"./node_modules/.bin/gulp watch --mkdocs\", \"build\": \"./node_modules/.bin/gulp build --production\" } ... }","title":"JSON"},{"location":"extensions/codehilite/#julia","text":"using MXNet mlp = @mx.chain mx.Variable(:data) => mx.FullyConnected(name=:fc1, num_hidden=128) => mx.Activation(name=:relu1, act_type=:relu) => mx.FullyConnected(name=:fc2, num_hidden=64) => mx.Activation(name=:relu2, act_type=:relu) => mx.FullyConnected(name=:fc3, num_hidden=10) => mx.SoftmaxOutput(name=:softmax) # data provider batch_size = 100 include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\")) train_provider, eval_provider = get_mnist_providers(batch_size) # setup model model = mx.FeedForward(mlp, context=mx.cpu()) # optimization algorithm optimizer = mx.SGD(lr=0.1, momentum=0.9) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider)","title":"Julia"},{"location":"extensions/codehilite/#lua","text":"local ffi = require(\"ffi\") ffi.cdef[[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi.os == \"Windows\" then function sleep(s) ffi.C.Sleep(s*1000) end else function sleep(s) ffi.C.poll(nil, 0, s * 1000) end end for i = 1,160 do io.write(\".\"); io.flush() sleep(0.01) end io.write(\"\\n\")","title":"Lua"},{"location":"extensions/codehilite/#mysql","text":"SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652';","title":"MySQL"},{"location":"extensions/codehilite/#php","text":"<?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route; use Symfony\\Component\\HttpFoundation\\Response; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction() { $number = mt_rand(0, 100); return new Response( '<html><body>Lucky number: '.$number.'</body></html>' ); } }","title":"PHP"},{"location":"extensions/codehilite/#protocol-buffers","text":"syntax = \"proto2\"; package caffe; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [packed = true]; } message BlobProto { optional BlobShape shape = 7; repeated float data = 5 [packed = true]; repeated float diff = 6 [packed = true]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [default = 0]; optional int32 channels = 2 [default = 0]; optional int32 height = 3 [default = 0]; optional int32 width = 4 [default = 0]; }","title":"Protocol Buffers"},{"location":"extensions/codehilite/#python","text":"\"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_string('data_dir', '/tmp/data/', 'Directory for storing data') mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True) sess = tf.InteractiveSession() # Create the model x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b)","title":"Python"},{"location":"extensions/codehilite/#ruby","text":"require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError; end class MissingCallback < StandardError; end class InvalidState < StandardError; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, &block @finity ||= Machine.new self, options, &block end # Return the names of all registered states. def states @finity.states.map { |name, _| name } end # Return the names of all registered events. def events @finity.events.map { |name, _| name } end end # Inject methods into the including class upon inclusion. def self.included base base.extend ClassMethods end end","title":"Ruby"},{"location":"extensions/codehilite/#xml","text":"<?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"> <!-- This is a sample comment --> <childTag attribute=\"Quoted Value\" another-attribute='Single quoted value' a-third-attribute='123'> <withTextContent>Some text content</withTextContent> <withEntityContent>Some text content with &lt;entities&gt; and mentioning uint8_t and int32_t</withEntityContent> <otherTag attribute='Single quoted Value'/> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"XML"},{"location":"extensions/footnotes/","text":"Footnotes Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - footnotes Usage The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document. Inserting the reference The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit. ^2 Inserting the content The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference. on a single line Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. on multiple lines Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote at the bottom of the page","title":"Footnotes"},{"location":"extensions/footnotes/#footnotes","text":"Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation.","title":"Footnotes"},{"location":"extensions/footnotes/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - footnotes","title":"Installation"},{"location":"extensions/footnotes/#usage","text":"The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document.","title":"Usage"},{"location":"extensions/footnotes/#inserting-the-reference","text":"The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit. ^2","title":"Inserting the reference"},{"location":"extensions/footnotes/#inserting-the-content","text":"The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference.","title":"Inserting the content"},{"location":"extensions/footnotes/#on-a-single-line","text":"Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit.","title":"on a single line"},{"location":"extensions/footnotes/#on-multiple-lines","text":"Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote at the bottom of the page","title":"on multiple lines"},{"location":"extensions/metadata/","text":"Metadata The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - meta Usage Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material. Setting a hero text Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts Linking sources When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output. Redirecting to another page It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url . Overrides Page title The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title. Page description The page description can also be overridden on a per-document level: description: Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value. Disqus As describe in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Metadata"},{"location":"extensions/metadata/#metadata","text":"The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context.","title":"Metadata"},{"location":"extensions/metadata/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - meta","title":"Installation"},{"location":"extensions/metadata/#usage","text":"Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material.","title":"Usage"},{"location":"extensions/metadata/#setting-a-hero-text","text":"Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts","title":"Setting a hero text"},{"location":"extensions/metadata/#linking-sources","text":"When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output.","title":"Linking sources"},{"location":"extensions/metadata/#redirecting-to-another-page","text":"It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url .","title":"Redirecting to another page"},{"location":"extensions/metadata/#overrides","text":"","title":"Overrides"},{"location":"extensions/metadata/#page-title","text":"The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title.","title":"Page title"},{"location":"extensions/metadata/#page-description","text":"The page description can also be overridden on a per-document level: description: Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value.","title":"Page description"},{"location":"extensions/metadata/#disqus","text":"As describe in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Disqus"},{"location":"extensions/permalinks/","text":"Permalinks Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document. Installation To enable permalinks, add the following to your mkdocs.yml : markdown_extensions: - toc: permalink: true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link Usage When enabled, permalinks are inserted automatically.","title":"Permalinks"},{"location":"extensions/permalinks/#permalinks","text":"Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document.","title":"Permalinks"},{"location":"extensions/permalinks/#installation","text":"To enable permalinks, add the following to your mkdocs.yml : markdown_extensions: - toc: permalink: true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link","title":"Installation"},{"location":"extensions/permalinks/#usage","text":"When enabled, permalinks are inserted automatically.","title":"Usage"},{"location":"extensions/pymdown/","text":"PyMdown Extensions PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme. Installation The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions: - pymdownx.arithmatex - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_generator: !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde Usage Arithmatex MathJax Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript: - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window.MathJax = { tex2jax: { inlineMath: [ [\"\\\\(\",\"\\\\)\"] ], displayMath: [ [\"\\\\[\",\"\\\\]\"] ] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", equationNumbers: { autoNumber: \"AMS\", }, unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign: \"left\", showProcessingMessages: false, messageStyle: \"none\" }; In your mkdocs.yml , include it with: extra_javascript: - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' Blocks Blocks are enclosed in :::tex $$...$$ which are placed on separate lines. Example: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Result: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Inline Inline equations need to be enclosed in :::tex $...$ : Example: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ Result: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ BetterEm BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes . Caret Caret makes it possible to highlight ^^inserted text^^. The portion of text that should be marked as added must be enclosed in two carets ^^...^^ . Critic Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} Details Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: ??? question \"How many Prolog programmers does it take to change a lightbulb?\" Yes. Emoji Emoji adds the ability to insert a :shit:-load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling :tada: !!! warning \"Legal disclaimer\" Material has no affiliation with [EmojiOne][15] which is released under [CC BY 4.0][16]. When including EmojiOne images or CSS, please read the [EmojiOne license][17] to ensure proper usage and attribution. InlineHilite InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. #!js var test = 0; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js . MagicLink MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses. Mark Mark adds the ability to ==highlight text== like it was marked with a ==text marker==. The portion of text that should be highlighted must be enclosed in two equal signs ==...== . SmartSymbols SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (<--, -->, <-->), trademark and copyright symbols ((c), (tm), (r)) and fractions (1/2, 1/4, ...). SuperFences SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs . Tasklist Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit [x] Nulla lobortis egestas semper [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est [ ] Vestibulum convallis sit amet nisi a tincidunt [x] In hac habitasse platea dictumst [x] In scelerisque nibh non dolor mollis congue sed et metus [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis [ ] Praesent sed risus massa [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Tilde Tilde provides an easy way to ~~strike through~~ cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#pymdown-extensions","text":"PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#installation","text":"The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions: - pymdownx.arithmatex - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_generator: !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde","title":"Installation"},{"location":"extensions/pymdown/#usage","text":"","title":"Usage"},{"location":"extensions/pymdown/#arithmatex-mathjax","text":"Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript: - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window.MathJax = { tex2jax: { inlineMath: [ [\"\\\\(\",\"\\\\)\"] ], displayMath: [ [\"\\\\[\",\"\\\\]\"] ] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", equationNumbers: { autoNumber: \"AMS\", }, unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign: \"left\", showProcessingMessages: false, messageStyle: \"none\" }; In your mkdocs.yml , include it with: extra_javascript: - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML'","title":"Arithmatex MathJax"},{"location":"extensions/pymdown/#blocks","text":"Blocks are enclosed in :::tex $$...$$ which are placed on separate lines. Example: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Result: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$","title":"Blocks"},{"location":"extensions/pymdown/#inline","text":"Inline equations need to be enclosed in :::tex $...$ : Example: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ Result: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$","title":"Inline"},{"location":"extensions/pymdown/#betterem","text":"BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes .","title":"BetterEm"},{"location":"extensions/pymdown/#caret","text":"Caret makes it possible to highlight ^^inserted text^^. The portion of text that should be marked as added must be enclosed in two carets ^^...^^ .","title":"Caret"},{"location":"extensions/pymdown/#critic","text":"Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==}","title":"Critic"},{"location":"extensions/pymdown/#details","text":"Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: ??? question \"How many Prolog programmers does it take to change a lightbulb?\" Yes.","title":"Details"},{"location":"extensions/pymdown/#emoji","text":"Emoji adds the ability to insert a :shit:-load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling :tada: !!! warning \"Legal disclaimer\" Material has no affiliation with [EmojiOne][15] which is released under [CC BY 4.0][16]. When including EmojiOne images or CSS, please read the [EmojiOne license][17] to ensure proper usage and attribution.","title":"Emoji"},{"location":"extensions/pymdown/#inlinehilite","text":"InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. #!js var test = 0; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js .","title":"InlineHilite"},{"location":"extensions/pymdown/#magiclink","text":"MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses.","title":"MagicLink"},{"location":"extensions/pymdown/#mark","text":"Mark adds the ability to ==highlight text== like it was marked with a ==text marker==. The portion of text that should be highlighted must be enclosed in two equal signs ==...== .","title":"Mark"},{"location":"extensions/pymdown/#smartsymbols","text":"SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (<--, -->, <-->), trademark and copyright symbols ((c), (tm), (r)) and fractions (1/2, 1/4, ...).","title":"SmartSymbols"},{"location":"extensions/pymdown/#superfences","text":"SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs .","title":"SuperFences"},{"location":"extensions/pymdown/#tasklist","text":"Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit [x] Nulla lobortis egestas semper [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est [ ] Vestibulum convallis sit amet nisi a tincidunt [x] In hac habitasse platea dictumst [x] In scelerisque nibh non dolor mollis congue sed et metus [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis [ ] Praesent sed risus massa [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi","title":"Tasklist"},{"location":"extensions/pymdown/#tilde","text":"Tilde provides an easy way to ~~strike through~~ cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"Tilde"}]}